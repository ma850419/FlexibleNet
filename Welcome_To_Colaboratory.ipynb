{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ma850419/FlexibleNet/blob/main/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from osgeo import gdal\n",
        "#filepath = r'/content/PRS_L1_STD_OFFL_20221217082013_20221217082018_0001_HCO_VNIR.tif'\n",
        "#filepath = r'/content/Sub_Sentinel2_.tif'\n",
        "filepath = r'/content/Hyperion_0_2007-03-07.tif'\n",
        "# https://stackoverflow.com/questions/43684072/how-to-import-multiple-bands-from-an-image-into-numpy\n",
        "# Load one GeoTIFF image using GDAL\n",
        "dataset = gdal.Open(filepath)\n",
        "#nodata_value = dataset.GetRasterBand(1).GetNoDataValue()\n",
        "projInfo = dataset.GetProjection()\n",
        "trans = dataset.GetGeoTransform()\n",
        "print(projInfo,dataset.RasterXSize,dataset.RasterYSize,dataset.RasterCount )\n",
        "#print(me)\n",
        "#image = np.zeros(( dataset.RasterXSize,dataset.RasterYSize,dataset.RasterCount))\n",
        "image = dataset.ReadAsArray()\n",
        "#image3 = np.transpose(image,(1,2,0))\n",
        "  # <class 'numpy.ndarray'>\n",
        "#print(image2.shape) \n",
        "#print(image.dtype)  \n",
        "#print(image.dtype)"
      ],
      "metadata": {
        "id": "L8pEg1GdIAjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysptools\n",
        "!pip install spectral"
      ],
      "metadata": {
        "id": "A3mfBmoA9J9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip testhyperion.zip"
      ],
      "metadata": {
        "id": "xeXGfr1Bj48y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import pysptools.classification as cls\n",
        "import matplotlib.pyplot as plt\n",
        "import pysptools.util as util\n",
        "import pysptools.eea as eea\n",
        "import pysptools.abundance_maps as amp\n",
        "import numpy as np\n",
        "\n",
        "n_emembers = 8\n",
        "\n",
        "\n",
        "def parse_ENVI_header(head):\n",
        "    ax = {}\n",
        "    ax['wavelength'] = head['wavelength']\n",
        "    ax['x'] = 'Wavelength - '+head['z plot titles'][0]\n",
        "    ax['y'] = head['z plot titles'][1]\n",
        "    return ax\n",
        "\n",
        "\n",
        "class Classify(object):\n",
        "    \"\"\"\n",
        "    For this problem NormXCorr works as well as SAM\n",
        "    SID was not tested.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, E, path, threshold, suffix):\n",
        "        print('Classify using SAM')\n",
        "        self.sam = cls.SAM()\n",
        "        self.sam.classify(data, E, threshold=threshold)\n",
        "        self.path = path\n",
        "        self.suffix = suffix\n",
        "\n",
        "    def get_single_map(self, idx):\n",
        "        return self.sam.get_single_map(idx, constrained=False)\n",
        "\n",
        "    def plot_single_map(self, idx):\n",
        "        self.sam.plot_single_map(self.path, idx, constrained=False, suffix=self.suffix)\n",
        "\n",
        "    def plot(self):\n",
        "        self.sam.plot(self.path, suffix=self.suffix)\n",
        "\n",
        "\n",
        "def get_endmembers(data, header, q, path, mask, suffix, output=False):\n",
        "    print('Endmembers extraction with NFINDR')\n",
        "    ee = eea.NFINDR()\n",
        "    U = ee.extract(data, q, maxit=5, normalize=True, ATGP_init=True, mask=mask)\n",
        "    if output == True:\n",
        "        ee.plot(path, axes=header, suffix=suffix)\n",
        "    return U\n",
        "\n",
        "\n",
        "def get_abundance_maps(data, U, umix_source, path, output=False):\n",
        "    print('Abundance maps with FCLS')\n",
        "    fcls = amp.FCLS()\n",
        "    amap = fcls.map(data, U, normalize=True)\n",
        "    if output == True:\n",
        "        fcls.plot(path, colorMap='jet', suffix=umix_source)\n",
        "    return amap\n",
        "\n",
        "\n",
        "def get_full_cube_em_set(data, header, path):\n",
        "    \"\"\" Return a endmembers set for the full cube and a region of interest (ROI).\n",
        "        The ROI is created using a small region of the\n",
        "        effluents leaving near the smokestack.\n",
        "    \"\"\"\n",
        "    # Take the endmembers set for all the cube\n",
        "    U = get_endmembers(data, header, n_emembers, path, None, 'full_cube', output=True)\n",
        "    # A threshold of 0.15 give a good ROI\n",
        "    cls = Classify(data, U, path, 0.15, 'full_cube')\n",
        "    # The endmember EM2 is use to define the region of interest\n",
        "    # i.e. the effluents region of interest\n",
        "    effluents = cls.get_single_map(2)\n",
        "    # Create the binary mask with the effluents\n",
        "    mask = (effluents > 0)\n",
        "    # Plot the mask\n",
        "    plot(mask, 'gray', 'binary_mask', path)\n",
        "    return U, mask\n",
        "\n",
        "\n",
        "def get_masked_em_set(data, header, path, mask):\n",
        "    \"\"\" Return a endmembers set that belong to the ROI (mask).\n",
        "    \"\"\"\n",
        "    # Use the mask to extract endmembers near the smokestack exit\n",
        "    U = get_endmembers(data, header, n_emembers, path, mask, 'masked', output=True)\n",
        "    return U\n",
        "\n",
        "\n",
        "def classification_analysis(data, path, E_masked):\n",
        "    # Note: the classification is done with NormXCorr instead of SAM\n",
        "    # Classify with the masked endmembers set\n",
        "    c = cls.NormXCorr()\n",
        "    c.classify(data, E_masked, threshold=0.15)\n",
        "    c.plot_single_map(path, 'all', constrained=False, suffix='masked')\n",
        "    c.plot(path, suffix='masked')\n",
        "    # Calculate the average image\n",
        "    gas = c.get_single_map(1, constrained=False)\n",
        "    for i in range(n_emembers - 1):\n",
        "        gas = gas + c.get_single_map(i+2, constrained=False)\n",
        "    gas = gas / n_emembers\n",
        "    # and plot it\n",
        "    plot(gas, 'Spectral', 'mean_NormXCorr', path)\n",
        "\n",
        "\n",
        "def unmixing_analysis(data, path, E_full_cube, E_masked):\n",
        "    # Calculate an unmixed average image at the ROI position.\n",
        "    # Each endmember belonging to E_masked takes place inside E_full_cube at\n",
        "    # the ROI position. Netx, we sum the abundance maps\n",
        "    # generated at this position. And finally a mean is calculated.\n",
        "    for i in range(n_emembers):\n",
        "        E_full_cube[1,:] = E_masked[i,:]\n",
        "        amaps = get_abundance_maps(data, E_full_cube, 'masqued_{0}'.format(i+1), path, output=False)\n",
        "        if i == 0:\n",
        "            mask = amaps[:,:,1]\n",
        "        else:\n",
        "            mask = mask + amaps[:,:,1]\n",
        "        plot(amaps[:,:,1], 'Spectral', 'FCLS_masqued_{0}'.format(i+1), path)\n",
        "    mask = mask / n_emembers\n",
        "    thresholded = (mask > 0.15) * mask\n",
        "    plot(thresholded, 'Spectral', 'mean_FCLS', path)\n",
        "\n",
        "\n",
        "def plot(image, colormap, desc, path):\n",
        "    plt.ioff()\n",
        "    img = plt.imshow(image, interpolation='none')\n",
        "    img.set_cmap(colormap)\n",
        "    plt.colorbar()\n",
        "    fout = osp.join(path, '{0}.png'.format(desc))\n",
        "    plt.savefig(fout)\n",
        "    plt.clf()"
      ],
      "metadata": {
        "id": "_HHDrlu_9u42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#------------------------------------------------------------------------------\n",
        "# Copyright (c) 2013-2014, Christian Therien\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#    http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "#------------------------------------------------------------------------------\n",
        "#\n",
        "# envi.py - This file is part of the PySptools package.\n",
        "#\n",
        "\n",
        "\"\"\"\n",
        "load_ENVI_file, load_ENVI_spec_lib functions\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import spectral.io.envi as envi\n",
        "\n",
        "def load_ENVI_file(file_name):\n",
        "    \"\"\"\n",
        "    Load the data and the header from an ENVI file.\n",
        "    It use the SPy (spectral) library. At 'file_name' give the envi header file name.\n",
        "    Parameters:\n",
        "        file_name: `path string`\n",
        "            The complete path to the file to load. Use the header file name.\n",
        "    Returns: `tuple`\n",
        "        data: `numpy array`\n",
        "            A (m x n x p) HSI cube.\n",
        "        head: `dictionary`\n",
        "            Starting at version 0.13.1, the ENVI file header\n",
        "     \"\"\"\n",
        "    img = envi.open(file_name)\n",
        "    head = envi.read_envi_header(file_name)\n",
        "    return np.array(img.load()), head\n",
        "\n",
        "\n",
        "def load_ENVI_spec_lib(file_name):\n",
        "    \"\"\"\n",
        "    Load a ENVI .sli file.\n",
        "    Parameters:\n",
        "        file_name: `path string`\n",
        "            The complete path to the library file to load.\n",
        "    Returns: `numpy array`\n",
        "        A (n x p) HSI cube.\n",
        "        head: `dictionary`\n",
        "            Starting at version 0.13.1, the ENVI file header\n",
        "    \"\"\"\n",
        "    sli = envi.open(file_name)\n",
        "    head = envi.read_envi_header(file_name)\n",
        "    return sli.spectra, head"
      ],
      "metadata": {
        "id": "JueMtgq8Cs9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#croppping black borders outside image\n",
        "def crop_image(img,tol=0):\n",
        "    # img is 2D or 3D image data\n",
        "    # tol  is tolerance\n",
        "    mask = img>tol\n",
        "    if img.ndim >=3:\n",
        "        mask = mask.all(2)\n",
        "    mask0,mask1 = mask.any(0),mask.any(1)\n",
        "    #print(np.ix_(mask1,mask0))\n",
        "    #print(me)\n",
        "    return img[np.ix_(mask1,mask0)]\n",
        "\n",
        "def crop_image_only_outside(img,tol=0):\n",
        "    # img is 2D or 3D image data\n",
        "    # tol  is tolerance\n",
        "    mask = img>tol\n",
        "    if img.ndim>=3:\n",
        "        mask = mask.all(2)\n",
        "    m,n = mask.shape\n",
        "    mask0,mask1 = mask.any(0),mask.any(1)\n",
        "    col_start,col_end = mask0.argmax(),n-mask0[::-1].argmax()\n",
        "    row_start,row_end = mask1.argmax(),m-mask1[::-1].argmax()\n",
        "    return img[row_start:row_end,col_start:col_end]"
      ],
      "metadata": {
        "id": "Ql2ncqmtvKYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Load the cube\n",
        "    data_path = '/content/'\n",
        "    home = '/content/'\n",
        "    result_path = os.path.join(home, 'results')\n",
        "    sample = 'testhyperion.hdr'\n",
        "    data_file = osp.join(data_path, sample)\n",
        "    data1, header = load_ENVI_file(data_file)\n",
        "    print(data1.shape)\n",
        "    #data2 = crop_image_only_outside(data1)\n",
        "    #print(data1.shape, data2.shape,data2.dtype)\n",
        "    #print(me)\n",
        "    if osp.exists(result_path) == False:\n",
        "        os.makedirs(result_path)\n",
        "\n",
        "    axes = parse_ENVI_header(header)\n",
        "\n",
        "    # Telops cubes are flipped left-right\n",
        "    # Flipping them again restore the orientation\n",
        "    data = np.fliplr(data1)\n",
        "    #print(data.shape)\n",
        "    U = get_endmembers(data, axes, 16, result_path, mask=None, suffix=None)\n",
        "    amaps = get_abundance_maps(data, U, None, result_path)\n",
        "  \n",
        "    # EM4 == quartz\n",
        "    #quartz = amaps[:,:,3]\n",
        "    #plot(quartz, 'Spectral', 'quartz', result_path)\n",
        "\n",
        "    # EM1 == background, we use the backgroud to isolate the drill core\n",
        "    # and define the mask\n",
        "    #mask = (amaps[:,:,0] < 0.2)\n",
        "    #plot(mask, 'Spectral', 'mask', result_path)\n",
        "\n",
        "    # Plot the quartz in color and the hematite in gray\n",
        "    #plot(np.logical_and(mask == 1, quartz <= 0.001) + quartz, 'Spectral', 'hematite+quartz', result_path)\n",
        "\n",
        "    # pixels stat\n",
        "    #rock_surface = np.sum(mask)\n",
        "    #quartz_surface = np.sum(quartz > 0.16)\n",
        "    #print('Some statistics')\n",
        "   # print('  Drill core surface (mask) in pixels:', rock_surface)\n",
        "   # print('  Quartz surface in pixels:', quartz_surface)\n",
        "    #print('  Hematite surface in pixels:', rock_surface - quartz_surface)"
      ],
      "metadata": {
        "id": "RQnrWt4KB724"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow as tf\n",
        "#tf.test.gpu_device_name()\n",
        "#!/opt/bin/nvidia-smi\n",
        "!pip install -U tensorflow-gpu"
      ],
      "metadata": {
        "id": "Nrhz2qUlzQAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#enhance image contrast brightness\n",
        "import cv2\n",
        "\n",
        "def adjust_contrast_brightness(img, contrast:float=1.0, brightness:int=0):\n",
        "    \"\"\"\n",
        "    Adjusts contrast and brightness of an uint8 image.\n",
        "    contrast:   (0.0,  inf) with 1.0 leaving the contrast as is\n",
        "    brightness: [-255, 255] with 0 leaving the brightness as is\n",
        "    \"\"\"\n",
        "    brightness += int(round(255*(1-contrast)/2))\n",
        "    return cv2.addWeighted(img, contrast, img, 0, brightness)"
      ],
      "metadata": {
        "id": "saSezEtxQOSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(np.logical_and(mask == 1, quartz <= 0.001) + quartz, 'Spectral', 'hematite+quartz', result_path)"
      ],
      "metadata": {
        "id": "dSTG659h-ZVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "#gradient = np.linspace(0, 1, 256)\n",
        "#gradient = np.vstack((gradient, gradient))\n",
        "#plt.imshow(gradient, aspect='auto', cmap=mpl.colormaps['Spectral'])\n",
        "#print(me)\n",
        "amaps1 = np.fliplr(amaps)\n",
        "print(amaps1.shape)\n",
        "print(amaps.shape)\n",
        "clustered3 = np.zeros((1872,1052,3))\n",
        "#f, axarr = \n",
        "plt.subplots(1,1)\n",
        "clustered3[:,:,0]=amaps1[:,:,5]\n",
        "clustered3[:,:,1]=amaps1[:,:,6]\n",
        "clustered3[:,:,2]=amaps1[:,:,9]\n",
        "plt.imshow(clustered3)\n",
        "plt.subplots(1,2)\n",
        "mx= (data1[:,:,5]/data1[:,:,5].max())*255.0\n",
        "mx2= (data1[:,:,16]/data1[:,:,16].max())*255.0\n",
        "mx3= (data1[:,:,29]/data1[:,:,29].max())*255.0\n",
        "clustered3[:,:,0]=mx\n",
        "clustered3[:,:,1]=mx2\n",
        "clustered3[:,:,2]=mx3\n",
        "clustered3=adjust_contrast_brightness(clustered3,10, 100)\n",
        "#print(clustered3.max())\n",
        "plt.imshow(clustered3)\n",
        "plt.subplots(2,1)\n",
        "clustered3[:,:,0]=amaps[:,:,5]\n",
        "clustered3[:,:,1]=amaps[:,:,6]\n",
        "clustered3[:,:,2]=amaps[:,:,9]\n",
        "plt.imshow(clustered3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wWSaKzs32qrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/testhyperion.zip"
      ],
      "metadata": {
        "id": "NctZguXBA0PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#from PIL import ImageEnhance\n",
        "#print(projInfo,image )\n",
        "f, axarr = plt.subplots(2,2)\n",
        "image3 = np.transpose(image1,(1,2,0))\n",
        "clustered3 = np.zeros((159,158,3))\n",
        "image4 = np.zeros((160,160,10))\n",
        "image5 = np.zeros((160,160,10))\n",
        "clustered3[:,:,0]=image3[:,:,5]\n",
        "clustered3[:,:,1]=image3[:,:,7]\n",
        "clustered3[:,:,2]=image3[:,:,3]\n",
        "#enh = ImageEnhance.Contrast(clustered3)\n",
        "#enh.enhance(1.8).show(\"30% more contrast\")\n",
        "#clustered3 = ((clustered3 - clustered3.min()) / (clustered3.max()-clustered3.min())) * 255\n",
        "axarr[0,1].imshow(clustered3)\n",
        "image2 = np.transpose(image,(1,2,0))\n",
        "clustered3 = np.zeros((159,158,3))\n",
        "clustered3[:,:,0]=image2[:,:,5]\n",
        "clustered3[:,:,1]=image2[:,:,7]\n",
        "clustered3[:,:,2]=image2[:,:,3]\n",
        "print(clustered3)\n",
        "axarr[1,1].imshow(clustered3)\n",
        "plt.show()\n",
        "image4[0:159,0:158,:]=image2\n",
        "image5[0:159,0:158,:]=image3\n",
        "image4[159:160,158:160,:]=0\n",
        "image5[159:160,158:160,:]=0\n",
        "print(image4.shape, image5.shape)\n"
      ],
      "metadata": {
        "id": "VNV_y8XNNkxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rast_arr= np.transpose(image2,(2,0,1))\n",
        "rast_arr=image\n",
        "print(rast_arr.shape)"
      ],
      "metadata": {
        "id": "QcfdGYn-X1eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install minisom"
      ],
      "metadata": {
        "id": "2qnG0fK6Xgol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SOM clustering\n",
        "\n",
        "import statistics\n",
        "from minisom import MiniSom\n",
        "mine=np.zeros((1231*1245,63))\n",
        "pixels2=np.zeros((1231*1245,63))\n",
        "pixels3=np.zeros((1231*1245,63))\n",
        "som_clustered=np.zeros((1231*1245,63))\n",
        "som = MiniSom(4, 4, 63, sigma=0.5,learning_rate=0.1, neighborhood_function='gaussian')\n",
        "#mine=zeros((512*512,4))\n",
        "#pixels2=zeros((600,512*512,4))\n",
        "#som_clustered=zeros((600,512*512,1))\n",
        "#for i in range(600):\n",
        "pixels2= image2.reshape(1231*1245,63)\n",
        "pixels3 = pixels2 != -999\n",
        "pixels2 = abs(pixels2)*pixels3/300.0\n",
        "#print( pixels2.min())\n",
        "som.random_weights_init(pixels2)\n",
        "starting_weights = som.get_weights().copy()  # saving the starting weights\n",
        "som.train(pixels2, 10000, random_order=False, verbose=True)\n",
        "print('quantization...')\n",
        "qnt = som.quantization(pixels2)  # quantize each pixels of the image\n",
        "    #print(qnt.shape)\n",
        "clustered = np.zeros((1231*1245,63))\n",
        "clustered1 = np.zeros((1231*1245,1))\n",
        "for j, q in enumerate(qnt):  # place the quantized values into a new image\n",
        "  sn = np.unravel_index(j,shape=((1231*1245)))\n",
        "    #print(sn)\n",
        "    #print(me)\n",
        "   \n",
        "  #print(q,(mean(q)*6).astype(np.uint8))\n",
        "  #print(me)\n",
        "  clustered[sn] = q[:] #(max(q)*6).astype(np.uint8) \n",
        "  #print(q[:]*255,round(q[:].max()*255))\n",
        "  #print(me)\n",
        "  #print((round(q[:].max()*16*300.0)))\n",
        "  #print(me)\n",
        "  clustered1[sn] = (round(q[:].max()*255))#.astype(np.uint8) #statistics.mean(q)\n",
        " # print(clustered1[sn])\n",
        "        #print(clustered.shape)\n",
        "#mine= np.append(mine,clustered,axis=0)#,axis=0)\n",
        "   # print(clustered1)\n",
        "#som_clustered[i] =  clustered1\n",
        "    #print(som_clustered[i])\n",
        "    #print(me)\n",
        "#print(mine.shape)"
      ],
      "metadata": {
        "id": "NLyWhKguYmoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "#print(clustered.shape, clustered1.shape)\n",
        "pixels2= pixels2.reshape((1231,1245,63))\n",
        "clustered2 = np.zeros((1231,1245))\n",
        "clustered3 = np.zeros((1231,1245,3))\n",
        "clustered3[:,:,0]=pixels2[:,:,60]\n",
        "clustered3[:,:,1]=pixels2[:,:,35]\n",
        "clustered3[:,:,2]=pixels2[:,:,20]\n",
        "clustered3 = cv2.pow(clustered3,0.6)\n",
        "# Convert the image from BGR to HSV color space\n",
        "clustered2 = clustered1.reshape(1231,1245)\n",
        "f, axarr = plt.subplots(2,2)\n",
        "plt.figure(figsize = (20,4))\n",
        "axarr[0,0].imshow(clustered2)\n",
        "#plt.show()\n",
        "axarr[0,1].imshow(clustered3)\n",
        "#plt.show()\n",
        "clustered3[:,:,0]=pixels2[:,:,50]\n",
        "clustered3[:,:,1]=pixels2[:,:,30]\n",
        "clustered3[:,:,2]=pixels2[:,:,15]\n",
        "clustered3 = cv2.pow(clustered3,0.7)\n",
        "axarr[1,0].imshow(clustered3)\n",
        "#plt.show()\n",
        "clustered3[:,:,0]=pixels2[:,:,30]\n",
        "clustered3[:,:,1]=pixels2[:,:,20]\n",
        "clustered3[:,:,2]=pixels2[:,:,10]\n",
        "axarr[1,1].imshow(clustered3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dlPPXg3X36lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(U.shape)"
      ],
      "metadata": {
        "id": "ckMUNJy8Kaw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = \"endmember4.tif\"\n",
        "imag=amaps1\n",
        "imag = np.transpose(imag,(2,0,1))\n",
        "print(imag.shape)\n",
        "driver = gdal.GetDriverByName(\"GTiff\")\n",
        "x_size = dataset.RasterXSize # Raster xsize\n",
        "y_size = dataset.RasterYSize # Raster ysize\n",
        "nband = 16 #dataset.RasterCount # number of bands\n",
        "NaN_rast=-999\n",
        "dataset_out = driver.Create(output_file, x_size, y_size,nband, gdal.GDT_Float32 )\n",
        "#dataset_out.WriteArray(imag[:,:,0].astype(np.float32))\n",
        "for band in range(len(imag)):\n",
        "  geo_transform = dataset.GetGeoTransform()\n",
        "  srs = dataset.GetProjectionRef()  # Projection\n",
        "  arr=imag[band]\n",
        "  #rast_arr[rast_arr == NaN_rast] = np.NaN\n",
        "  dataset_out.SetGeoTransform(geo_transform)\n",
        "  dataset_out.SetProjection(srs)\n",
        "  print(band)\n",
        "  dataset_out.GetRasterBand(band+1).WriteArray(arr)\n",
        "dataset_out.FlushCache()\n",
        "dataset_out = None"
      ],
      "metadata": {
        "id": "4tiUhUFx5MkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from osgeo import osr\n",
        "output_file = \"out10.tif\"\n",
        "imag=amaps1\n",
        "#clustered2 = np.zeros((1231,1245))\n",
        "#clustered2 = clustered1.reshape(1231,1245)\n",
        "# Create gtif\n",
        "#rast_arr= np.zeros((image.shape))\n",
        "#rast_arr= np.copy((image))\n",
        "#print(rast_arr)\n",
        "driver = gdal.GetDriverByName(\"GTiff\")\n",
        "x_size = dataset.RasterXSize # Raster xsize\n",
        "y_size = dataset.RasterYSize # Raster ysize\n",
        "nband = 16 #dataset.RasterCount # number of bands\n",
        "NaN_rast=-999\n",
        "dataset_out = driver.Create(output_file, x_size, y_size,nband, gdal.GDT_Float32 )\n",
        "# top left x, w-e pixel resolution, rotation, top left y, rotation, n-s pixel resolution\n",
        "#dst_ds.SetGeoTransform( [ -180, 0.025, 0, 90, 0, -0.025 ] )\n",
        "#print(clustered2[900:1000,900:1000], clustered2.dtype)\n",
        "#print(me)\n",
        "# set the reference info \n",
        "band = 0\n",
        "if type(imag) == tuple:\n",
        "  print('0')\n",
        "  rast_arr = np.array(imag[band])\n",
        "if str(type(dataset)) == \"<class 'osgeo.gdal.Dataset'>\":\n",
        "  print('2')\n",
        "  geo_transform = dataset.GetGeoTransform()\n",
        "  x_size = dataset.RasterXSize  # Raster xsize\n",
        "  y_size = dataset.RasterYSize  # Raster ysize\n",
        "  #print(x_size,y_size)\n",
        "  srs = dataset.GetProjectionRef()  # Projection\n",
        "elif str(type(dataset)) == \"<class 'affine.Affine'>\":\n",
        "  print('3')\n",
        "  geo_transform = (dataset[2], dataset[0], dataset[1], dataset[5], dataset[3], dataset[4])\n",
        "  rast_arr = imag[band,:,:]\n",
        "  x_size = int(rast_arr.shape[1])\n",
        "  y_size = int(rast_arr.shape[0])\n",
        "driver = gdal.GetDriverByName(\"GTiff\")\n",
        "dataset_out = driver.Create(output_file, x_size, y_size, nband, gdal.GDT_Float32)\n",
        "    #end auxiliar\n",
        "for band in range(1,nband):\n",
        "  if type(imag) == tuple:\n",
        "    print('Iam ')\n",
        "    rast_arr = np.array(imag[band])\n",
        "  if str(type(dataset)) == \"<class 'osgeo.gdal.Dataset'>\":\n",
        "    print('Iam here')\n",
        "    geo_transform = dataset.GetGeoTransform()\n",
        "    x_size = dataset.RasterXSize  # Raster xsize\n",
        "    y_size = dataset.RasterYSize  # Raster ysize\n",
        "    #print(x_size,y_size)\n",
        "    srs = dataset.GetProjectionRef()  # Projection\n",
        "  elif str(type(dataset)) == \"<class 'affine.Affine'>\":\n",
        "    print('Iam here here')\n",
        "    geo_transform = (dataset[2], dataset[0], dataset[1], dataset[5], dataset[3], dataset[4])\n",
        "    rast_arr = imag[band,:,:]\n",
        "    x_size = int(rast_arr.shape[1])\n",
        "    y_size = int(rast_arr.shape[0])\n",
        "        #PROCESS RASTERIO NUMPY\n",
        "  else:\n",
        "    print('Iam here here here')\n",
        "    geo_transform = (dataset[1][2], dataset[1][0], dataset[1][1], dataset[1][5], dataset[1][3], dataset[1][4])\n",
        "    rast_arr = np.array(dataset[0])\n",
        "    x_size = int(rast_arr.shape[2])\n",
        "    y_size = int(rast_arr.shape[1])\n",
        "  #rast_arr[rast_arr == NaN_rast] = np.NaN\n",
        "  dataset_out.SetGeoTransform(geo_transform)\n",
        "  dataset_out.SetProjection(srs)\n",
        "  print(band)\n",
        "  dataset_out.GetRasterBand(band).WriteArray(imag[:,:,band])#.astype(np.float32))\n",
        "#for band in range(1,nband):\n",
        "  #dst_ds.SetGeoTransform(trans)\n",
        "#dst_ds.ImportFromWkt(projInfo)\n",
        "  #dst_ds.SetProjection( projInfo )\n",
        "  #dst_ds.GetRasterBand(band).WriteArray(image)\n",
        "dst_ds.FlushCache()\n",
        "#dst_ds = None\n"
      ],
      "metadata": {
        "id": "FyBc1zT4eFqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unique(list1):\n",
        " \n",
        "    # insert the list to the set\n",
        "    list_set = set(list1)\n",
        "    # convert the set to the list\n",
        "    unique_list = (list(list_set))\n",
        "    #for x in unique_list:\n",
        "        #print(x)\n",
        "    return unique_list"
      ],
      "metadata": {
        "id": "Cxr1qbkrrnb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1=[]\n",
        "list1= np.append(list1,clustered)\n",
        "#list1=clustered1.tolist()\n",
        "l= np.zeros(60)\n",
        "u=unique(list1)\n",
        "print(u)\n"
      ],
      "metadata": {
        "id": "REnOM6z5rqAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=plt.hist(clustered)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "1hMtBWvylSsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, models\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "#from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import  confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "#import pydot\n",
        "#import pydot_ng as pydot\n",
        "from keras.utils import plot_model\n",
        "from keras.layers import Input, Dense, BatchNormalization"
      ],
      "metadata": {
        "id": "bDLKnoWfpIho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating subimage of size 32X32\n",
        "height=16\n",
        "width = 16\n",
        "#subim = np.zeros((38,32,32,63))\n",
        "subim = np.zeros((10,16,16,10))\n",
        "subim1 = np.zeros((10,16,16,10))\n",
        "#imgwidth, imgheight, bands= image2[15:1231,29:1245,:].shape\n",
        "imgwidth, imgheight, bands= image2[:,:,:].shape\n",
        "imgwidth1, imgheight1, bands1= image3[:,:,:].shape\n",
        "#print(imgwidth, imgheight, bands)\n",
        "for k in range(0,10):\n",
        "  for i in range(0,imgheight,height):\n",
        "    for j in range(0,imgwidth,width):\n",
        "      #box = (j, i, j+width, i+height)\n",
        "      subim[k]= image4[j:j+width,i:i+height,:]\n",
        "#print(imgwidth, imgheight, bands)\n",
        "for k in range(0,10):\n",
        "  for i in range(0,imgheight,height):\n",
        "    for j in range(0,imgwidth,width):\n",
        "      #box = (j, i, j+width, i+height)\n",
        "      subim1[k]= image5[j:j+width,i:i+height,:]\n",
        "#image3 = np.zeros((imgwidth, imgheight, bands))\n",
        "#image3 = image2[15:1231,29:1245,:]\n",
        "#print(imgwidth, imgheight, bands)\n",
        "#for k in range(0,38):\n",
        " # for i in range(0,imgheight,height):\n",
        "  #  for j in range(0,imgwidth,width):\n",
        "      #box = (j, i, j+width, i+height)\n",
        "  #    subim[k]= image3[j:j+width,i:i+height,:]\n",
        "print(subim1, subim)"
      ],
      "metadata": {
        "id": "fFrQhAu-13yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,  x_test, y_train, y_test = train_test_split(subim1,subim,random_state=2020,test_size=0.2)\n",
        "#x_train= train_images\n",
        "#y_train =train_labels1\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "#print(im1[0])\n",
        "#x_test=train_images\n",
        "#y_test = train_label\n",
        "#x_train= train_images\n",
        "#y_train =train_label\n",
        "#print(x_test.shape)"
      ],
      "metadata": {
        "id": "dh0Z-6yB6Kcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet(img_size,num_classes):\n",
        "    # input layer shape is equal to patch image size\n",
        "    inputs = keras.Input(shape=img_size + (10,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\",data_format='channels_last')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256, 512]:#, 256, 512]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\",data_format='channels_last')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\",data_format='channels_last')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\",data_format='channels_last')(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\",data_format='channels_last')(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [512, 256, 128, 64]:# [512, 256, 128, 64, 32]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\",data_format='channels_last')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\",data_format='channels_last')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2,data_format='channels_last')(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.UpSampling2D(2,data_format='channels_last')(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\",data_format='channels_last')(residual)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\",data_format='channels_last')(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "jAchW7MS6SL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "img_size=(16, 16)\n",
        "num_classes=10\n",
        "model = build_unet(img_size,num_classes)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ncyMt4DzB-VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "hsUACuELCWYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x8ysSFsNsVFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oyPyVyAJsUmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train , y_train , epochs=50, steps_per_epoch=8, batch_size=4, validation_data=(x_test , y_test))"
      ],
      "metadata": {
        "id": "LtkZf4NJCc92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "import matplotlib.image as img\n",
        "import pandas as pd\n",
        "import os\n",
        "from os.path import exists\n",
        "from pathlib import Path\n",
        "\n",
        "#with open('C:/Users/ma850/OneDrive/Documents/banana_spectral_signatures/banana_healthy_1a.dat', 'r') as dat_file:\n",
        " #   with open('C:/Users/ma850/OneDrive/Documents/banana_spectral_signatures/banana_healthy_1a.csv', 'w') as csv_file:\n",
        "csv_dir =  r'/content/'\n",
        "onlyfilenames = [f for f in listdir(csv_dir) if os.path.isfile(csv_dir+f)]\n",
        "for file in onlyfilenames:\n",
        "    print(file)\n",
        "    filename, extension = os.path.splitext(file)\n",
        "    if extension == '.csv':\n",
        "        df = pd.read_csv(csv_dir+file,header =0)#, chunksize=1000)\n",
        "        print(df.shape)\n",
        "specsig = (df.iloc[:,:].values).astype('float32')\n",
        "print(specsig.shape)"
      ],
      "metadata": {
        "id": "TIO6F0oNrCC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filtering A spectril signature\n",
        "\n",
        "import numpy\n",
        "print(specsig[:,0])\n",
        "specsig[:,0:1]\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(specsig[:,0],specsig[:,1])\n",
        "specsig1 = numpy.zeros((2151,30))\n",
        "specsig2 = numpy.zeros((2151,30))\n",
        "leng=len(specsig)\n",
        "#print(leng)\n",
        "specsig1[:,0] = specsig[:,0]\n",
        "for i in range(leng):\n",
        "    for j in range(1,30,1):\n",
        "        if(specsig[i,j] >=0 and specsig[i,j] <= 1.0):\n",
        "            specsig1[i,j]=specsig[i,j]\n",
        "        else:\n",
        "            specsig1[i,j]= 0\n",
        "#print(specsig1[:,0:1])       \n",
        "specsig2[:,0] = specsig[:,0]\n",
        "specsig2[0:991,1:30]=specsig[0:991,1:30]\n",
        "specsig2[991:1096,1:30]=specsig[991:1096,1:30]\n",
        "specsig2[1096:1441,1:30]= specsig[1096:1441,1:30]\n",
        "specsig2[1441:1606,1:30]=0\n",
        "specsig2[1606:2151,1:30]= specsig[1606:2151,1:30]\n",
        "print(specsig2.shape)\n",
        "plt.subplot(1, 2 , 1) # row 1, col 2 index 1\n",
        "#plt.plot(specsig2[0:991,0],specsig2[0:991,2],'b.')\n",
        "#plt.plot(specsig2[1096:1441,0],specsig2[1096:1441,2],'b.')\n",
        "#plt.plot(specsig2[1606:2100,0],specsig2[1606:2100,2],'b.')\n",
        "plt.plot(specsig2[:,0],specsig2[:,1:],'b.')\n",
        "plt.subplot(2, 2, 2) \n",
        "plt.plot(specsig[:,0],specsig[:,1:],'r^')\n",
        "plt.show"
      ],
      "metadata": {
        "id": "zOgbcB5c8Z7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading FWHM file for prisma\n",
        "csv_dir = \"/content/\"\n",
        "file='Hyperion_FWHM.csv'\n",
        "df = pd.read_csv(csv_dir+file,header =0)\n",
        "print(df.shape)\n",
        "fwhm= (df.iloc[:,:].values).astype('float32')"
      ],
      "metadata": {
        "id": "fxrACeHr-IBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resmapling spectral signatures to Prisma VNIR using FWHM\n",
        "#resampling Hyperion images\n",
        "#specsig3 = np.zeros((63,31))\n",
        "#specsig3[:,0]=fwhm[:,2]\n",
        "#specsig3[:,1]=fwhm[:,3]\n",
        "specsig3 = np.zeros((198,31))\n",
        "specsig3[:,0]=fwhm[:,0]\n",
        "specsig3[:,1]=fwhm[:,1]\n",
        "for j in range(1,30):\n",
        "   # n=0\n",
        "    for i in range(0,198):\n",
        "        f= round(fwhm[i,1])\n",
        "        k= round(f+fwhm[i,2])\n",
        "        s=0\n",
        "        l=0\n",
        "        for m in range (0,2151):\n",
        "           \n",
        "            if specsig2[m,0] >= f and specsig2[m,0]<=k:\n",
        "                s= specsig2[m,j]+ s\n",
        "                l=l+1\n",
        "        av= s/l\n",
        "        specsig3[i,j+1]= av\n",
        " "
      ],
      "metadata": {
        "id": "UPnb_LMY8oBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_dir = \"/content/\"\n",
        "file='Hyperion_FWHM_resampled.csv'\n",
        "pd.DataFrame(specsig3).to_csv(csv_dir+file)"
      ],
      "metadata": {
        "id": "j94t67on_X7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import pysptools.classification as cls\n",
        "image3 = np.transpose(image,(1,2,0))/10000.0\n",
        "print( image3.shape, image3.max())\n",
        "U2= np.transpose(U,(1,0))\n",
        "specsig4=specsig3[:,2:]\n",
        "print(U.shape, image3.shape, image3.max())\n",
        "path = '/content/results'\n",
        "#E-masked= U\n",
        "c = cls.SAM()\n",
        "myim=c.classify(image3, U, threshold=0.1)\n",
        "#classification_analysis(image3, path, U)\n",
        "#cls.SAM(image3, specsig4,0.1,None)"
      ],
      "metadata": {
        "id": "Ekwc-FOijY_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #c.plot_single_map(path, 1, constrained=False, suffix= None)\n",
        "#plot(myim,'Spectral', None, path)\n",
        "print(myim.max())"
      ],
      "metadata": {
        "id": "WbU4tWLIQtUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#while True:pass\n",
        "a = []\n",
        "while 1:\n",
        "    a.append(\"1\")"
      ],
      "metadata": {
        "id": "2OWEkT0-hyRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "split_bar = '='*20\n",
        "memory_info = psutil.virtual_memory()._asdict()\n",
        "print(f\"{split_bar} Memory Usage {split_bar}\")\n",
        "for k,v in memory_info.items():\n",
        "  print(k, v)\n",
        "print(f\"{split_bar} CPU Usage {split_bar}\")\n",
        "print(f\"CPU percent: {psutil.cpu_percent()}%\")"
      ],
      "metadata": {
        "id": "kFMfEGMfC_qS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}